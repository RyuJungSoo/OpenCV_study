# 5.1 이동 및 크기 변환
## 어파인 변환
영상의 **기하학적 변환(Geometric Transformation)** 은 영상을 구성하는 픽셀의 위치를 조정하여 형상을 변형하는 것이다. 대표적으로 **이동, 확대 및 축소, 회전** 등이 있다. 
이들은 입력과 출력 간의 좌표 변환을 기반으로 수행되며 이러한 연산을 일반적으로 **어파인 변환**이라고 한다.           
좌표 변환은 기본적으로 입력 좌표에 특정 변환함수를 적용하여 새로운 좌표를 생성하는 과정으로 아래 식으로 표현할 수 있다.             
<img src="https://user-images.githubusercontent.com/81175672/179739345-0e51b15e-6386-46a2-8271-c3a943533813.JPG"  width="700" height="200"/>              
***
변환함수 *T*에 따라서 기하학적 변환 특징이 정해지며, 2D 영상에서 어파인 변환은 아래와 같이 입력과 출력의 관계를 정의한다.                
<img src="https://user-images.githubusercontent.com/81175672/179739714-b99a7dea-5d55-430c-bdb6-67f99dc7ccfe.JPG"  width="700" height="200"/>              
해당 축에 곱해지는 상수(a와 e)만 있을 경우에는 **크기 변환** 이 수행되고, 더해지는 상수(c와 f)는 **이동 변환**을 수행한다.                 
그리고 각각의 축에 상수곱을 하고 합하는 경우(a와 b, d와 e)는 **회전 변환**을 수행할 수 있다.              
a~f로 이루어진 변환을 결정하는 행렬을 **어파인 변환 행렬** 이라고 한다.        
***
## 이동 변환                      
**이동 변환** - 영상을 수평 또는 수직 방향으로 이동시키는 연산                
<img src="https://user-images.githubusercontent.com/81175672/179748812-7192a280-4c7b-45e4-afda-9660137baebe.JPG"  width="700" height="200"/>           
f = 0, c > 0 -> 영상이 오른쪽으로 이동     
f = 0, c < 0 -> 영상이 왼쪽으로 이동             
f > 0, c = 0 -> 영상이 아래로 이동             
f < 0, c = 0 -> 영상이 위로 이동            
각 상수의 부호와 크기에 따라서 영상의 이동이 결정된다.                  
<img src="https://user-images.githubusercontent.com/81175672/179754404-7a8aaeb7-5358-4b00-a95f-005e521e586e.png"  width="800" height="400"/>                      
(출처: https://velog.io/@codren/%EC%98%81%EC%83%81-%ED%8C%8C%EC%9D%BC%EC%9D%98-%EA%B8%B0%ED%95%98%ED%95%99%EC%A0%81-%EB%B3%80%ED%99%98)                  
***
## 크기 변환         
**크기 변환** - 영상을 전반적으로 확대 또는 축소하는 연산                      
<img src="https://user-images.githubusercontent.com/81175672/179752403-17baff2f-9666-47a2-b0dc-3f6c4ebdb685.JPG"  width="700" height="200"/>               
a와 e가 0 이상의 값을 가져야 한다. 만약 0으로 한다면, 영상이 한 점으로 표시되고 아무런 정보를 얻을 수 없다. 
0 < (a, e) < 1 -> 영상이 축소                 
(a, e) = 1 -> 입력 영상의 크기를 유지               
(a, e) > 1 -> 영상이 확대            
<img src="https://user-images.githubusercontent.com/81175672/179754719-0590eec2-af45-43cb-81a9-26148a47cd2b.png"  width="800" height="400"/>           
(출처: https://velog.io/@codren/%EC%98%81%EC%83%81-%ED%8C%8C%EC%9D%BC%EC%9D%98-%EA%B8%B0%ED%95%98%ED%95%99%EC%A0%81-%EB%B3%80%ED%99%98)                      
***
## 어파인 변환 함수
OpenCV에서는 어파인 변환을 수행하는 **warpAffine() 함수**를 지원한다. 어파인 변환 행렬은 사용자가 임의로 지정할 수도 있고, **getAffineTransform() 함수** 를 이용하여 
계산할 수도 있다.           
***
**getAffineTransform(src, dst)**                
기능: 3개의 입력점(src)을 출력점(dst)으로 변환하기 위한 어파인 변환 행렬을 계산한다. ( 점 세개의 이동정보를 알면 어파인 행렬로 표시가 가능하며 세개의 이동정보로 마지막 점의 위치를 유추할 수 있다.)                                     
| 매개변수 | 의미 |
| --- | --- |
| src | 변환 전 3개의 점 위치 (float32) |
| dst | 변환 후 3개의 점 위치 (float32) |
***
**warpAffine(src, M, dsize, dst=None, flags=None, borderMode=None, borderValue=None)**                     
기능: 입력 영상(src)을 주어진 변환 행렬(M)을 지용하여 어파인 변호나하고 지정된 크기(dsize)의 영상으로 만든다.                       
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 영상 |
| M | 변환 행렬 (2x3 행렬) |
| dsize | 출력 영상의 크기 |
| dst | 출력 영상 |
| flags | 보간법 방식 지정(INTER_NEAREST, INTER_LINEAR, INTER_CUBIC, INTER_AREA 등이 있음. WARP_INVERSE_MAP을 추가 지정하면 역방향 변환을 수행함(dst -> src)) |
| borderMode | 영상의 가장 자리를 처리하는 방식 지정(BORDER_TRANSPARENT)이면, 입력 영상에 대응하는 점이 없을 경우에는 출력 영상의 값을 유지 |
| borderValue | borderMode가 BORDER_CONSTANT인 경우에 해당 픽셀을 채울 값 (기본값은 0) |           
***
또한, OpenCV에서는 크기 변환을 위한 **resize() 함수** 를 제공하며, 원형은 다음과 같다. 크기 변환만을 할 경우에는 이 함수를 이용하는 것이 편리하다.         

***
**resize(src, dsize, dst=None, fx=None, fy=None, interpolation=None)**                     
기능: 입력 영상(src)을 주어진 크기(dsize)로 조절한다.                    
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 영상 |
| dsize | 출력 영상의 크기 (0이면, fx와 fy에 의하여 결정됨) |
| dst | 크기가 조정된 결과 영상 |
| fx | 영상의 가로 크기를 조정 (0이면, dsize의 가로 크기를 입력 영상의 가로 크기로 나누어 결정됨) |
| fy | 영상의 세로 크기를 조정 (0이면, dsize의 세로 크기를 입력 영상의 세로 크기로 나누어 결정됨) |
| interpolation | 보간법 지정 (cv2.INTER_NEAREST, cv2.INTER_LINER, cv2.INTER_CUBIC, INTER_AREA 등이 있음) |
***
```py
# 관련 라이브러리 선언
import numpy as np
import cv2
from imgRead import imgRead
from createFolder import createFolder

# 영상 읽기
img1 = imgRead("img11.jpg", cv2.IMREAD_GRAYSCALE, 320, 240)

# 이동 변환
h, w = img1.shape
tlans_x = 10; tlans_y = 25
point1_src = np.float32([[15, 20], [50,70], [130, 140]]) # 입력점
point1_dst = np.float32(point1_src + [tlans_x, tlans_y]) # 출력점
affine_mat1 = cv2.getAffineTransform(point1_src, point1_dst) # 직접 어파인 행렬 계산
user_mat1 = np.float32([[1,0,tlans_x], [0,1,tlans_y]]) # 변환 행렬(사용자 입력)

res1 = cv2.warpAffine(img1, affine_mat1, (w,h)) 
res2 = cv2.warpAffine(img1, user_mat1, (w,h))

# 크기 변환
scale_x = 0.8; scale_y = 0.6
background = np.full(shape=[h,w], fill_value=0, dtype = np.uint8)
user_mat2 = np.float32([[scale_x,0,0], [0,scale_y,0]]) # 변환 행렬(사용자 입력)

res3 = cv2.warpAffine(img1, user_mat2, (w,h)) # warpAffine 함수 사용
res4 = cv2.resize(img1, (0,0), None, scale_x, scale_y) # resize 함수 사용
background[:(int)(h*scale_y), :(int)(w*scale_x)] = res4; res4 = background

# 이동 및 크기 변환
user_mat3 = np.float32([[0.4, 0, 100], [0, 0.6, 50]]) # 변환 행렬(사용자 입력)
res5 = cv2.warpAffine(img1, user_mat3, (w,h))

# 결과 영상 출력
displays = [("input1", img1),
            ("res1", res1),
            ("res2", res2),
            ("res3", res3),
            ("res4", res4),
            ("res5", res5)]
for (name, out) in displays:
    cv2.imshow(name, out)

# 키보드 입력을 기다린 후 모든 영상창 닫기
cv2.waitKey(0)
cv2.destroyAllWindows()

# 영상 저장
save_dir = './code_res_imgs/c2_geometric'
createFolder(save_dir)
for (name, out) in displays:
    cv2.imwrite(save_dir + "/" + name + ".jpg", out)
```
## 출력 결과
<입력 영상>            
<img src="https://user-images.githubusercontent.com/81175672/180110482-3396150e-b4b1-4a1b-ad11-05bd5b4a9407.jpg"  width="320" height="240"/>               
<이동 변환(getAffineTransform 이용)>                  
<img src="https://user-images.githubusercontent.com/81175672/180110975-8112b54c-e639-40fa-b3ca-ad8e39a4c18f.jpg"  width="320" height="240"/>                     
<이동 변환(사용자 입력)>                   
<img src="https://user-images.githubusercontent.com/81175672/180110998-a5ba44e9-2894-4b6d-9564-c368954863ff.jpg"  width="320" height="240"/>  
<크기 변환(warpAffine 이용)>            
<img src="https://user-images.githubusercontent.com/81175672/180111013-8fd1b883-4abf-483b-b287-1f8dbd91c969.jpg"  width="320" height="240"/>  
<크기 변환(resize 이용)>                   
<img src="https://user-images.githubusercontent.com/81175672/180111039-8da7c4d8-51b6-4506-8b77-e78ffe35b64f.jpg"  width="320" height="240"/>  
<이동과 크기 변환>                   
<img src="https://user-images.githubusercontent.com/81175672/180111056-e5d784e2-e97f-4eca-994b-469035488f46.jpg"  width="320" height="240"/> 
***
# 5.2 회전 변환
**회전 변환** 은 영상을 특정한 축을 기준으로 회전하는 연산으로 다음의 관계를 가진다.        
<img src="https://user-images.githubusercontent.com/81175672/180111784-ab26a125-2fdd-4656-8387-edc9399ecd94.JPG"  width="600" height="200"/>             
회전 변환에 사용할 상수는 삼각함수를 이용하여 계산할 수 있다. 기본적인 삼각함수를 이용하여 p점과 p'은 아래와 같이 표현할 수 있다.
<img src="https://user-images.githubusercontent.com/81175672/180118706-97bf4534-89e8-400b-a700-5c1dfaa49fdb.JPG"  width="800" height="400"/>                  
<img src="https://user-images.githubusercontent.com/81175672/180119359-339ba588-d645-43ba-8061-2ff91082c52a.JPG"  width="800" height="200"/>           
p' 점의 코사인과 사인 내부의 덧셈을 **삼각함수 공식** 으로 풀이하면 다음과 같이 정리할 수 있다.              
<img src="https://user-images.githubusercontent.com/81175672/180126250-b29804db-3e97-4a05-b2a6-e81c6447be9e.JPG"  width="900" height="500"/>              
여기서 r x cosθ<sub>1</sub>와 r x sinθ<sub>1</sub>은 점 p의 i와 j의 위치이므로 이들 값을 이용하여 아래와 같이 정리할 수 있다.          
<img src="https://user-images.githubusercontent.com/81175672/180126568-9d0e6168-fc97-43f5-8572-8eaeca794c9d.JPG"  width="800" height="400"/>         
정리된 수식을 통하여 점 p가 θ<sub>2</sub>만큼 회전한 p' 좌표를 알 수 있다. 수식의 형태가 어파인 변환 행렬과 동일하며 
**a = cosθ, b = -sinθ, d = sinθ, e = cosθ** 가 된다.               
[선형대수로 증명하는 방법](https://blog.naver.com/hyorinnam/222644199902)                                     
***
OpenCV에서는 회전 변환을 위한 어파인 행렬 변환을 계산해 주는 **getRotationMatrix2D() 함수** 를 지원하며 원형은 다음과 같다.            
***
**getRotationMatrix2D(center, angle, scale)**                     
기능: 입력 영상(src)을 주어진 중심축(center)을 기준으로 특정 각도(angle)만큼 회전할 수 있는 어파인 변환 행렬을 계산한다.                    
| 매개변수 | 의미 |
| --- | --- |
| center | 회전 축의 원점 |
| angle | 회전 각도 (도(°) 단위, 양수이면 반시계방향, 음수이면 시계방향으로 회전함) |
| scale | 회전 변환 후 출력 영상을 확대 또는 축소할 비율 |
***
회전 변환은 이동 및 크기 변환과 동일하게 **warpAffine() 함수**를 이용하면 된다. 특정 각도의 회전에 대해서는 **rotate() 함수**를 지원하며, 90°의 상수배 회전이 가능하다.       
또한, 회전 변환 이외에 영상의 좌우 또는 상하를 반전시키는 **flip() 함수** 도 지원한다.
**rotate(src, rotateCode, dst=None)**                     
기능: 입력 영상(src)을 정해진 각도(rotateCode)로 회전시킨다.                         
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 행렬 |
| rotateCode | 회전 각도를 지정하는 플래그 (ROTATE_90_CLOCKWISE, ROTATE_180, ROTATE_90_COUNTERCLOCKWISE) |
| dst | 입력 행렬과 동일한 자료형의 출력 행렬 |                   
***
**flip(src, flipCode, dst=None)**                     
기능: 입력 영상(src)을 지정된 형태(flipCode)로 반전시킨다.                        
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 행렬 |
| flipCode | 반전을 지정하는 플래그 (0: 상하 반전, >0: 좌우 반전, <0: 상하 및 좌우 반전) |
| dst | 입력 행렬과 동일한 자료형의 출력 행렬 |                 
***
```py
# 관련 라이브러리 선언
import numpy as np
import cv2
from imgRead import imgRead
from createFolder import createFolder

# 영상 읽기
img1 = imgRead("img11.jpg", cv2.IMREAD_GRAYSCALE, 320, 240)

# 영상 회전
h, w = img1.shape
c_h = h // 2; c_w = w // 2 # 회전의 중심점

rot_mat1 = cv2.getRotationMatrix2D((c_w, c_h), 45, 1) # 45도 반시계 회전 행렬
rot_mat2 = cv2.getRotationMatrix2D((c_w, c_h), -45, 1) # 45도 시계 회전 행렬

res1 = cv2.warpAffine(img1, rot_mat1, (w,h)) 
res2 = cv2.warpAffine(img1, rot_mat2, (w,h))
res3 = cv2.rotate(img1, cv2.ROTATE_90_CLOCKWISE) # rotate 함수 사용
res4 = cv2.flip(img1, 1) # flip 함수로 좌우 반전
res5 = cv2.flip(img1, 0) # flip 함수로 상하 반전
res6 = cv2.flip(img1, -1) # flip 함수로 상하 및 좌우 반전

# 결과 영상 출력
displays = [("input1", img1),
            ("res1", res1),
            ("res2", res2),
            ("res3", res3),
            ("res4", res4),
            ("res5", res5),
            ("res6", res6)]
for (name, out) in displays:
    cv2.imshow(name, out)

# 키보드 입력을 기다린 후 모든 영상창 닫기
cv2.waitKey(0)
cv2.destroyAllWindows()

# 영상 저장
save_dir = './code_res_imgs/c2_rotate'
createFolder(save_dir)
for (name, out) in displays:
    cv2.imwrite(save_dir + "/" + name + ".jpg", out)
```            
## 출력 결과
<입력 영상>            
<img src="https://user-images.githubusercontent.com/81175672/180110482-3396150e-b4b1-4a1b-ad11-05bd5b4a9407.jpg"  width="320" height="240"/>               
<45° 반시계 회전>                  
<img src="https://user-images.githubusercontent.com/81175672/180110975-8112b54c-e639-40fa-b3ca-ad8e39a4c18f.jpg"  width="320" height="240"/>                     
<45° 시계 회전>                   
<img src="https://user-images.githubusercontent.com/81175672/180110998-a5ba44e9-2894-4b6d-9564-c368954863ff.jpg"  width="320" height="240"/>  
<90° 회전>            
<img src="https://user-images.githubusercontent.com/81175672/180111013-8fd1b883-4abf-483b-b287-1f8dbd91c969.jpg"  width="320" height="240"/>  
<좌우 반전>                   
<img src="https://user-images.githubusercontent.com/81175672/180111039-8da7c4d8-51b6-4506-8b77-e78ffe35b64f.jpg"  width="320" height="240"/>  
<상하 및 좌우 반전>                   
<img src="https://user-images.githubusercontent.com/81175672/180111056-e5d784e2-e97f-4eca-994b-469035488f46.jpg"  width="320" height="240"/> 
***

# 5.3 투시 변환              
어파인 변환은 3개의 기준점들의 이동 전후 관계를 통하여 영상의 형상을 변형하였다. 하지만 3개의 점을 사용하기 때문에 좀 더 복잡한 형상으로의 변화는 어렵다. 즉, 3개의 점만으로 형태의 변화를 다 포함하지 못하는 경우에는 원하는 형상을 얻지 못한다. (나머지 한 점의 이동이 결정되기 때문)     
예를 들어, 아래 그림처럼 직사각형 형태의 영상을 사다리꼴의 형태로 변환하기 위해서는 **4개의 점에 대한 이동 관계** 가 필요하다.
<img src="https://user-images.githubusercontent.com/81175672/180176941-a7a96a46-5948-461d-80d4-c57daea393af.JPG"  width="400" height="300"/> 
***
**투시 변환** 은 4개의 기준점을 이용하여 임의의 변형을 수행하며, 아래와 같이 입력과 출력의 관계를 정의한다.       
<img src="https://user-images.githubusercontent.com/81175672/180182820-ddb058a7-4663-4c17-b1f9-4633e2c8dfaf.JPG"  width="800" height="400"/>                    
위 좌표계는 **동차 자표계** 상에 표현되어 있다. 이 좌표계는 사영기하학에서 무한 원점과 같은 확장된 점의 표현을 위하여 만든 좌표계이다. 사영기하학은 3차원의 입체 물체를 
2차원의 평면에 나타내기 위하여 평행선들과 소실점의 관계를 연구하였고, 그 결과로 다양한 분야에서 유용하게 사용되고 있는 원근법을 탄생시킨 분야이다.           
[동차 좌표계에 대해서](https://jw910911.tistory.com/7)                   
***
수식에서 ω는 동차좌표계에서 무한대 요소를 표현하기 위하영 사용한다. 즉 ω에 따라서 어떤 점이 우리가 일반적으로 사용하는 **유클리드 공간** 에서의 한 점이 될 수도 있고, 
무한대에 있는 점이 될 수도 있다. 수학적으로 ω는 다음의 수식을 표현하는 것이다.                  
<img src="https://user-images.githubusercontent.com/81175672/180187903-cff97e54-a134-4a17-b55e-a9c0895529a0.JPG"  width="300" height="300"/>          
**z가 1이면** -> 앞에서 지금까지 살펴본 좌표계와 동일                 
**z가 0로 수렴할수록** -> 무한대의 점으로 대응하게 된다.                   
동차 좌표계의 수식을 전개하면 다음과 같이 출력 좌표를 얻게 된다.               
<img src="https://user-images.githubusercontent.com/81175672/180189375-10c18fbe-f912-4c37-a379-0f64947a2fe6.JPG"  width="500" height="300"/>                  
최종적으로 우리가 원하는 출력 좌표 (i', j')는 아래와 같이 계산할 수 있다.          
<img src="https://user-images.githubusercontent.com/81175672/180193571-c835123b-7bb2-400e-83b8-51f6f5c1b552.JPG"  width="500" height="300"/>             
위의 식에서 필요한 변수들의 값을 구하기 위해서는 **4개 이상의 점에 대한 이동 전후의 좌표** 가 필요하다. 4개의 점에 대한 좌표를 이용하여 연립방정식을 만들고, 이들을 
행렬의 형태로 표현하면 다음과 같다.          
<img src="https://user-images.githubusercontent.com/81175672/180225054-066a8ede-83a8-47f0-89c0-4281f7b586d4.JPG"  width="800" height="500"/>              
위 함수에서 8x8 행렬의 역행렬을 구하고 출력점에 곱하여 변수들의 값을 계산할 수 있다. OpenCV에서는 어파인 변환과 마찬가지로, 투시 변환의 변환 행렬을 구할 수 있는 
**getPerspectiveTransform() 함수** 와 변환을 수행하는 **warpPerspective() 함수** 를 지원한다. 이들의 원형은 다음과 같다.          
***
**getPerspectiveTransform(src, dst, solveMethod=None)**                  
기능: 4개의 입력 점(src)을 출력점(dst)으로 변환하기 위한 투시 변환 행렬을 계산한다.           
| 매개변수 | 의미 |
| --- | --- |
| src | 변환 전 4개의 점 위치 (float32) |
| dst | 변환 후 4개의 점 위치 (float32) |
| solveMethod | 행렬의 변수를 계산하기 위한 방식 지정 (DECOMP_LU, DECOMP_SVD, DECOMP_EIG, DECOMP_CHOLESKY, DECOMP_QR, DECOMP_NORMAL) |
***
**warpAffine(src, M, dsize, dst=None, flags=None, borderMode=None, borderValue=None)**                  
기능: 입력 영상(src)을 주어진 변환 행렬(M)을 이용하여 투시 변환하고 지정된 크기(dsize)의 영상으로 만든다.          
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 영상 |
| M | 변환 행렬 |
| dsize | 출력 영상의 크기 |
| dst | 출력 영상 |
| flags | 보간법 방식 지정(INTER_NEAREST, INTER_LINEAR, INTER_CUBIC, INTER_AREA 등이 있음. WARP_INVERSE_MAP을 추가 지정하면 역방향 변환을 수행함(dst->src)) |
| borderMode | 영상의 가장 자리를 처리하는 방식 지정(BORDER_TRANSPARENT이면, 입력 영상에 대응하는 점이 없을 경우에는 출력 영상의 값을 유지) |
| borderValue | borderMode가 BORDER_CONSTANT인 경우에 해당 픽셀을 채울 값 (기본값은 0) |
***
```py
# 관련 라이브러리 선언
import numpy as np
import cv2
from imgRead import imgRead
from createFolder import createFolder

# 영상 읽기
img1 = imgRead("img12.jpg", cv2.IMREAD_GRAYSCALE, 320, 240)

# 투시 변환 수행
h, w = img1.shape
point1_src = np.float32([[1,1], [w-10, 10], [5, h-5], [w-4, h-4]])
point1_dst = np.float32([[15,15], [w-60,15], [10,h-25], [w-100,h-50]])
point2_src = np.float32([[148,145], [168,144], [136,223], [188,222]])
point2_dst = np.float32([[136,145], [188,144], [136,223], [188,222]])

per_mat1 = cv2.getPerspectiveTransform(point1_src, point1_dst)
per_mat2 = cv2.getPerspectiveTransform(point2_src, point2_dst)
res1 = cv2.warpPerspective(img1, per_mat1, (w,h))
res2 = cv2.warpPerspective(img1, per_mat2, (w,h))

# 결과 영상 출력
displays = [("input1", img1),
            ("res1", res1),
            ("res2", res2)]
for (name, out) in displays:
    cv2.imshow(name, out)

# 키보드 입력을 기다린 후 모든 영상창 닫기
cv2.waitKey(0)
cv2.destroyAllWindows()

# 영상 저장
save_dir = "./code_res_imgs/c2_perspective"
createFolder(save_dir)
for (name, out) in displays:
    cv2.imwrite(save_dir + "/" + name + ".jpg", out)

```
## 출력 결과
<입력 영상>            
<img src="https://user-images.githubusercontent.com/81175672/180414685-175c624e-7716-4a57-9adf-cabd4ea7f024.jpg"  width="320" height="240"/>               
<영상의 전체 형상 변환 <- 영상의 외곽에 위치한 점을 기준점으로 잡고 전반적인 형태를 변형한 것>                  
<img src="https://user-images.githubusercontent.com/81175672/180414726-2e3ff3a7-db08-4447-b622-bf40736d9adb.jpg"  width="320" height="240"/>                     
<특정 위치(기차 복도)를 직사각형 형상으로 변환 <- 입력 영상의 복도의 원근감을 없애고 수평으로 보이도록 변환한 것>                   
<img src="https://user-images.githubusercontent.com/81175672/180414779-5e4cde0f-d287-4dd9-a0c9-6efca8cc8317.jpg"  width="320" height="240"/>  
***
# 5.4 모폴로지 연산
**모폴로지** 는 관심 대상의 형태를 분석하고 처리하는 분야이다. 대상의 경계, 블록 등의 형태를 표현하는데 필요한 정보를 추출하기 위한 전처리 기법으로 많이 사용된다.             
(ex. 이진 영상에서 잡음 제거 또는 공간 채우기, 불명확한 대상 물체의 영역 구분)                           
모폴로지 연산은 주어진 필터에 대응하는 입력 영상의 픽셀값이 **유의미한 값** 을 가지는지 여부를 판단하여 출력 영상의 픽셀값을 정하는 것으로 두 가지 규칙으로 구성된다.        
***
입력 영상과 필터가 모두 **이진화(0,1)** 되어 있다고 가정해 보자.                
**첫번째 규칙** - 필터에서 1에 해당하는 영역에 대응하는 입력 영상의 모든 위치가 1이면 출력은 1이 된다. (AND 연산과 동일)                   
**두번째 규칙** - 필터에서 1에 해당하는 영역에 대응하는 입력 영상의 위치 중에서 한 곳이라도 1이면 출력은 1이 된다 (OR 연산과 동일)             
<img src="https://user-images.githubusercontent.com/81175672/180678677-e84c3ea9-199e-41fb-83f0-5d5e6f932222.JPG"  width="900" height="400"/>                 

## 5.4.1 침식 팽창
**침식(Erosion)** 과 **팽창(Dilation)** 은 앞 절에서 설명한 기본적인 규칙만을 적용한 것이다.                 

### 침식
- 첫 번째 규칙을 적용한 것, 잡음을 제거하거나 관심 대상의 돌출부를 제거하여 형상을 단순화할 수 있다. 
- 관심 대상 내부에 빈 곳이 존재할 경우에는 해당 공간이 확대되는 문제가 발생할 수 있다.                
- 이진 영상에서 관심 대상(1로 표현)의 영역은 줄어들고 배경(0으로 표현) 영역은 확대되는 효과가 있다.                

### 침식
- 두 번째 규칙을 적용한 것, 관심 대상 내부에 존재하는 공간을 채울 수 있다.
- 배경에 존재하는 잡음도 확대될 수 있다.            
- 침식과는 반대로 관심 대상의 영역이 확대되고 배경 영역이 줄어드는 효과가 있다.             

침식과 팽창을 위한 필터는 다양한 형태로 정의될 수 있다. 사용자가 임의로 만들어 사용할 수도 있으며, 특정한 형태(사각형, 더하기 모양, 타원)를 사용하고자 할 경우에는 
OpenCV에서 제공하는 **getStructuringElement() 함수** 를 사용할 수 있다.                    
침식과 팽창 연산을 위하여 **erode()** 와 **dilate()** 함수도 제공한다.                        
***

**getStructuringElement(shape, ksize, anchor=None)**
기능: 지정된 크기(ksize)의 필터에 원하는 형상(shape)으로 값을 채운다.
| 매개변수 | 의미 |
| --- | --- |
| shape | 필터에서 적용할 형상 지정(MORPH_RECT, MORPH_CROSS, MORPH_ELLIPSE) |
| ksize | 필터의 크기 |
| anchor | 좌표의 원점 위치를 지정 ((-1,-1)이면 필터의 중심을 원점으로 사용함) |

***
**erode(src, kernel, dst=None, anchor=None, iterations=None, borderType=None, borderValue=None)**
기능: 입력 영상(src)에 주어진 구조(kernel)를 이용하여 **침식 연산**을 지정된 횟수(iterations)만큼 수행한다.        
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 영상 |
| kernel | 연산에 사용할 구조 (UMat()이면 3x3 크기의 MORPH_RECT 형상을 사용) |
| dst | 출력 영상 |
| anchor | 좌표의 원점 위치를 지정 ((-1,-1)이면 필터의 중심을 원점으로 사용함) |
| iterations | 연산의 반복 횟수 |
| borderType | 영상의 가장 자리를 처리하는 방식 지정 (BORDER_CONSTANT, BORDER_REPLICATE, BORDER_REFLECT, MORDER_WRAP 등이 있음) |
| borderValue | borderType가 BORDER_CONSTANT인 경우에 해당 픽셀을 채울 값 (기본값은 double형의 양수 최댓값인 DBL_MAX) |
***
**dilate(src, kernel, dst=None, anchor=None, iterations=None, borderType=None, borderValue=None)**
기능: 입력 영상(src)에 주어진 구조(kernel)를 이용하여 **팽창 연산**을 지정된 횟수(iterations)만큼 수행한다.
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 영상 |
| kernel | 연산에 사용할 구조 (UMat()이면 3x3 크기의 MORPH_RECT 형상을 사용) |
| dst | 출력 영상 |
| anchor | 좌표의 원점 위치를 지정 ((-1,-1)이면 필터의 중심을 원점으로 사용함) |
| iterations | 연산의 반복 횟수 |
| borderType | 영상의 가장 자리를 처리하는 방식 지정 (BORDER_CONSTANT, BORDER_REPLICATE, BORDER_REFLECT, MORDER_WRAP 등이 있음) |
| borderValue | borderType가 BORDER_CONSTANT인 경우에 해당 픽셀을 채울 값 (기본값은 double형의 양수 최댓값인 DBL_MAX) |
***
그레이 영상에 이 함수들을 적용하면 필터에 대응하는 입력 영상의 값 중에서 최솟값 또는 최댓값을 반환하는 연산을 수행한다.            
erode() 함수는 필터에 대응하는 값 중에서 가장 작은 값을 결괏값으로 반환하고, dilate() 함수는 가장 큰 값을 반환한다.              
이를 통ㅇ하여 영상 내에 존재한 객체들의 구조를 축소 및 확대한다.
```py
# 관련 라이브러리 선언
import cv2
from imgRead import imgRead
from createFolder import createFolder

# 트랙바 호출함수
def nothing(x):
    pass

# 홀수 확인 함수
def check_odd(num):
    if num % 2 == 0:
        num += 1
    return num

# 실행 함수
def set_run(pos):
    global img1
    global img_index

    # 트랙바 설정
    method = cv2.getTrackbarPos('method', "morphology") # 침식 또는 팽창
    itr = cv2.getTrackbarPos('iter', "morphology") # 연산의 반복 횟수
    ksize = cv2.getTrackbarPos('ksize', "morphology") # 필터의 크기
    run = cv2.getTrackbarPos('run', "morphology") # 실행 여부

    if run == 1: # run이 1이면 실행
        ksize = check_odd(ksize) # ksize 홀수 확인
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize)) # ksize x ksize 사각형 필터

        if method == 0: # method가 0이면 침식
            res = cv2.erode(img1, kernel, iterations=itr) # 침식
        else: # method가 1이면 팽창
            res = cv2.dilate(img1, kernel, iterations=itr) # 팽창

        # 사진 저장
        cv2.imshow("morphology", res)
        cv2.imwrite(save_dir + "/res" + str(img_index) + ".jpg", res)
        img_index += 1

# 영상 읽기
img1 = imgRead('img9.jpg', cv2.IMREAD_GRAYSCALE, 320, 240)

# 트랙바 생성
img_index = 1
save_dir = "./code_res_imgs/c2_erodeDilate"
createFolder(save_dir)

cv2.namedWindow('morphology')
cv2.createTrackbar('method', 'morphology', 0, 1, nothing)
cv2.createTrackbar('ksize', 'morphology', 3, 10, nothing)
cv2.createTrackbar("iter", 'morphology', 1, 10, nothing)
cv2.createTrackbar("run", 'morphology', 0, 1, set_run)
cv2.setTrackbarPos("method", "morphology", 0)
cv2.setTrackbarPos("ksize", "morphology", 3)
cv2.setTrackbarPos("iter", "morphology", 1)
cv2.setTrackbarPos("run", "morphology", 0)

cv2.imshow("morphology", img1)
cv2.waitKey(0)
cv2.destroyAllWindows() 

```
**<실행 화면>**                          
<img src="https://user-images.githubusercontent.com/81175672/180716776-624783ab-f6a6-44c9-933c-848ed27231a9.JPG"  width="400" height="700"/> 

## 5.4.2 열기 닫기
침식과 팽창은 관심 대상의 형상과 크기에 대하여 의도치 않은 결과를 가져올 수도 있다. **열기(Opening)** 와 **닫기(closing)** 는 침식과 팽창을 순차적으로 수행하여 위에서 
언급한 문제점을 최소화하는 기법이다.               
**열기** - 침식을 먼저 수행하고 그 결과 영상에 팽창을 수행한다.                    
**닫기** - 팽창을 먼저 수행한 후에 침식을 수행한다.            
두 기법 모두 침식과 팽창을 순차적으로 사용하기에 관심 대상의 크기 변화가 미비하다.               
### 열기
- 먼저 침식을 수행하여, 전반적으로 대상의 크기를 줄이면서 윤곽선의 돌출 영역을 제거하거나 소수의 픽셀으로 연결되어 있는 부분의 연결을 끊는다.           
- 다음으로 팽창을 수행하여 윤곽선의 크기를 다시 확대하면서 인접한 픽셀 간의 연결성을 보완한다.             
- 결과적으로 윤곽 부위를 부드럽게 하면서, 주변에 인접한 잡음처럼 보이는 영역들과의 연결성을 끊는 효과를 가진다.

### 닫기
- 먼저 팽창을 수행하여 대상의 형상에서 오목하게 들어간 부분이나 공간을 채운다.
- 그리고 침식을 수행하여 윤곽 부분의 미세하게 돌출된 부분을 제거한다.
- 결과적으로 열기와 유사하게 윤곽 부위를 부드럽게 하고 대상의 공간을 채우는 효과를 가진다.            

OpenCV에서는 침식과 팽창을 포함한 열기와 닫기를 수행할 수 있는 **morphologyEx() 함수** 를 지원하며, 원형은 아래와 같다.        


[모폴로지 연산에 대해서](https://bkshin.tistory.com/entry/OpenCV-19-%EB%AA%A8%ED%8F%B4%EB%A1%9C%EC%A7%80Morphology-%EC%97%B0%EC%82%B0-%EC%B9%A8%EC%8B%9D-%ED%8C%BD%EC%B0%BD-%EC%97%B4%EB%A6%BC-%EB%8B%AB%ED%9E%98-%EA%B7%B8%EB%A0%88%EB%94%94%EC%96%B8%ED%8A%B8-%ED%83%91%ED%96%87-%EB%B8%94%EB%9E%99%ED%96%87)              

**morphologyEx(src, op, kernel, dst=None, anchor=None, iterations=None, borderType=None, borderValue=None)**
기능: 입력 영상(src)에 주어진 구조(kernel)를 이용하여 모폴로지 연산(op)을 지정된 횟수(iterations)만큼 수행한다.        
| 매개변수 | 의미 |
| --- | --- |
| src | 입력 영상 |
| op | 모폴로지 연산 지정(MORPH_ERODE, MORPH_DILATE, MORPH_OPEN, MORPH_CLOSE, MORPH_GRADIENT, MORPH_TOPHAT, MORPH_BLACKHAT, MORPH_HITMISS) |
| kernel | 연산에 사용할 구조 (UMat()이면 3x3크기의 MORPH_RECT 형상을 사용) |
| dst | 출력 영상 |
| anchor | 좌표의 원점 위치를 지정 ((-1,-1)이면 필터의 중심을 원점으로 사용함) |
| iterations | 연산의 반복 횟수 |
| borderType | 영상의 가장자리를 처리하는 방식 지정(BORDER_CONSTANT, BORDER_REPLICATE, BORDER_REFLECT, BORDER_WRAP 등이 있음) |
| borderValue | borderType가 BORDER_CONSTANT인 경우에 해당 픽셀을 채울 값 (기본값은 double형의 양수 최댓값인 DBL_MAX) |
***
```py
# 관련 라이블러리 선언
import numpy as np
import cv2
from imgRead import imgRead
from createFolder import createFolder

# 영상 읽기
img1 = imgRead("img13.jpg", cv2.IMREAD_GRAYSCALE, 320, 240)

# 모폴로지 연산 수행
methods = [cv2.MORPH_OPEN,
           cv2.MORPH_CLOSE,
           cv2.MORPH_GRADIENT,
           cv2.MORPH_TOPHAT,
           cv2.MORPH_BLACKHAT,
           cv2.MORPH_HITMISS]

ress = []
for method in methods:
    res = cv2.morphologyEx(img1, method, cv2.UMat(), iterations=1)
    ress.append(res)

# 결과 영상 출력
displays = [("input1", img1),
            ("res1", ress[0]),
            ("res2", ress[1]),
            ("res3", ress[2]),
            ("res4", ress[3]),
            ("res5", ress[4]),
            ("res6", ress[5])]
for (name, out) in displays:
    cv2.imshow(name, out)

# 키보드 입력을 기다린 후 모든 영상창 닫기
cv2.waitKey(0)
cv2.destroyAllWindows()

# 영상 저장
save_dir = "./code_res_imgs/c2_morphology"
createFolder(save_dir)
for (name, out) in displays:
    cv2.imwrite(save_dir + "/" + name + ".jpg", out)
```
### 출력 결과
<입력 그레이 영상>            
<img src="https://user-images.githubusercontent.com/81175672/180750710-92a53804-c261-4866-8f70-b6e34d63d8c4.jpg"  width="320" height="240"/>               
<MORPH_OPEN>                  
<img src="https://user-images.githubusercontent.com/81175672/180750739-f24eb4fc-3627-4c12-aab6-5cb0c71afde5.jpg"  width="320" height="240"/>                     
<MORPH_CLOSE>                   
<img src="https://user-images.githubusercontent.com/81175672/180750767-5908bb51-5059-4425-a5c7-dccd6764afee.jpg"  width="320" height="240"/>  
<MORPH_GRADIENT>            
<img src="https://user-images.githubusercontent.com/81175672/180750813-b6298190-72f9-4950-aeea-ce96054fc9ca.jpg"  width="320" height="240"/>  
<MORPH_TOPHAT>                   
<img src="https://user-images.githubusercontent.com/81175672/180750855-5d785f32-b32d-428e-8e59-f3a8b11936ab.jpg"  width="320" height="240"/>  
<MORPH_BLACKHAT>                   
<img src="https://user-images.githubusercontent.com/81175672/180750918-30fcf02e-2ae3-4edc-8815-36c3bb7e7366.jpg"  width="320" height="240"/>        
<MORPH_HITMISS>                   
<img src="https://user-images.githubusercontent.com/81175672/180751217-a0e1c46c-80e2-452e-ab94-19e3364ea9dd.jpg"  width="320" height="240"/> 
***

